# -Databricks-x-dbt-End-To-End-Data-Engineering-Project-with-flight-dataset
Built a big data engineering pipeline using tools like Databricks, dbt and Delta Live Tables with PySpark: ingesting raw data via Autoloader, and modelling it using dimensional design including Slowly Changing Dimensions (SCDs). Also used Unity Catalog for metadata and access control, and scheduled pipelines to deliver analytics-ready datasets.

Bronze Layer Incremental Data Ingestion

<img width="990" height="326" alt="image" src="https://github.com/user-attachments/assets/b83f7120-2fd4-4746-a2cb-ac5023e4c8ea" />

Silver Layer Using DLT Pipeline

<img width="716" height="648" alt="image" src="https://github.com/user-attachments/assets/5f865af6-1994-4cf4-bfb9-3b6a6259103d" />


<img width="944" height="573" alt="image" src="https://github.com/user-attachments/assets/54995dc7-895a-45ca-91fa-f945f122c65b" />
